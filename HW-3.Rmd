---
title: "MATH 216 Homework 3"
author: "Kyler Blodgett"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(Quandl))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(pander))
suppressPackageStartupMessages(library(Rmisc))
```


## Admistrative:

Please indicate

* Who you collaborated with: Laney, Christian, Paul
* Roughly how much time you spent on this HW: 10 hours
* What gave you the most trouble: Creating the 2x2 contingency table in 1(c). And manipulating the data in question 2 so that weeks didn't appear as "Week 12" but as actual dates. The "odds" part of interpreting the log regression coefficients in question 1 was a little tricky, but office hours helped. 
* Any comments you have: 


## Data

* You must first copy the file `profiles.csv` from `HW-2` to the `data` folder
in the `HW-3` directory
* We also consider all 222,540 songs played in the Reed College pool hall
jukebox from Nov 30, 2003 to Jan 22, 2009 (included in `HW-3` folder). 

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("data/profiles.csv", header=TRUE) %>% 
  tbl_df()
jukebox <- read.csv("data/jukebox.csv", header=TRUE) %>% 
  tbl_df()
```





## Question 1:

For this question we will be picking up from where we left off in HW-2,
specifically the OkCupid dataset.


### a)

Using your exploratory data analysis from HW-2, fit a logistic regression to
predict individual's gender and interpret your results.When fitting the logistic regression, you can put both the categorical variable and the numerical variable you've chosen in the same model

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles1 <- mutate(profiles, is.female = ifelse(sex=="f", 1, 0)) %>%
  separate(ethnicity, c("eth1", "eth_rest"), sep=",") %>%
  na.omit(eth1)

model <- glm(is.female ~ height + eth1, family = binomial, data=profiles1)
summary(model)
pander(model)

profiles_eth <- profiles1 %>%
  group_by(eth1) %>%
  tally()

profiles <- mutate(profiles, is.female = ifelse(sex=="f", 1, 0)) 
mean(profiles$is.female)

ggplot(data=profiles_eth, aes(x=reorder(eth1, -n), y=n)) +
  geom_bar(stat= "Identity") +
  ggtitle("Proprortion of Primary Ethnicities among Users who Identified") +
  labs(x="Ethnicities", y="Number of Users") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here, I choose height as my continuous variable and first listed ethnicity ("eth1") as my categorical variable in predicting sex. Many of the model's predictor variables have a statistically significant effect on the odds of being female, the dependent variable (P-value < 0.05, with the excepton of indian and pacific islander ethnicities). After raising both sides of the equation to the power of e, coefficients represent the multiplicative effect of a unit increase in the predictor variable on the odds that a given user is female. Thus, the model predicts that an inch increase in hieght is associated with a decrease of a factor of 0.516 (exp(B1-hat)) in odds of being female. The suggestion that taller users are less likely to be female makes intuitive sense. 

We interpret the categorical variable "ethnicity" in a slightly different way. Because the variables are all dummy variables, the regression coefficients return their effect as compared to a base ethnic category. In our case, the base is Asian, so we interpret the coefficients as follows. Identifying one's primary ethnicity as "black" increases the odds of a user being female by exp(B2-hat), or 4.353, relative to an asian of equal height. This same calculation for other ethnicities is as follows:
Hispanic/Latin; 1.932
Middle Eastern; 1.827
Native American; 2.971
White; 1.938
Indian and Pacific Islander ethnicities are found not to have a statistically significant impact on the odds of being female. 

It is important to bear in mind that in only considering individuals that list at least one ethnicity, the model only considers around 12% of users, or 6859 observations. However, we are pretty protected from selection bias since among the users who listed an ethnicity, 38% are female, compared with 40% in the full data set. 

### b)

Plot a histogram of the fitted probabilities $\widehat{p}_i$ for all users $i=1,
\ldots, n=59946$ in your dataset.

```{r, echo=FALSE, fig.width=12, fig.height=6}
hist(fitted(model))
```

Note again that because of the way I coded the ethnicity categorical variable, only users that listed at least one ethnicity are included in the observations that my model considered. This population is about 12% of the total user population. 

### c)

Use a *decision threshold* of $p^*=0.5$ to make an explicit prediction for each
user $i$'s sex and save this in a variable `predicted_sex`. In other words, for user $i$

* If $\widehat{p}_i > p^*$, set `predicted_sex = 1` i.e. they are female
* If $\widehat{p}_i < p^*$, set `predicted_sex = 0` i.e. they are male

Display a 2 x 2 contigency table of `sex` and `predicted_sex` i.e. compare the 
predicted sex to the actual sex of all users. The sum of all the elements in
your table should be $n=59946$. Comment on how well our predictions fared.

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles1 <- profiles1 %>%
  na.omit(height) %>%
  mutate(pred= predict(model)) %>%
  mutate(predicted_sex = ifelse(pred>=0.5, 1, 0)) %>%
  mutate(pred_male_true = ifelse(predicted_sex ==0 & is.female==0, 1, 0)) %>% 
  mutate(pred_male_false = ifelse(predicted_sex ==0 & is.female==1, 1, 0)) %>% 
  mutate(pred_fem_true = ifelse(predicted_sex ==1 & is.female==1, 1, 0)) %>%
  mutate(pred_fem_false = ifelse(predicted_sex ==1 & is.female==0, 1, 0)) 

sum(profiles1$pred_male_true)
sum(profiles1$pred_male_false)
sum(profiles1$pred_fem_true)
sum(profiles1$pred_fem_false)

possible_outcomes <- c("pred_male_true", "pred_male_false", "pred_fem_true", "pred_fem_false")
amount <- c(sum(profiles1$pred_male_true), sum(profiles1$pred_male_false), sum(profiles1$pred_fem_true), sum(profiles1$pred_fem_false))

predict.data <- data.frame(possible_outcomes, amount)
kable(head(predict.data), format= "markdown")
```

I know this doesn't quite fit the contingency table form you showed in class, but I hope it's still clear. For reference, "pred_male_true" represents the number of users for which my model accurately predicted male. The other labels follow the same pattern. 

We see this is a fairly accurate model, as it predicts 83% of males correctly and 84% of females correctly. As I discussed in 1(b), the elements do not sum to 59946 since my model only considers users that submitted at least one ethnicity. 


## Question 2:

Using the jukebox data, plot a time series of the number of songs played each
week over the entire time period. i.e.

* On the x-axis present actual dates (not something like Week 93, which doesn't 
mean anything to most people).
* On the y-axis present the total number of songs.

What seasonal (i.e. cyclical) patterns do you observe?

```{r, echo=FALSE, fig.width=12, fig.height=6}

jukebox1 <- jukebox %>%
  mutate(new_date = parse_date_time(jukebox$date_time, "%a %b %d %H %M! %S! %Y!")) %>%
  mutate(week = week(new_date)) %>%
  mutate(year = year(new_date)) %>%
  #unite("week_year", week, year, sep="-") %>%
  group_by(week, year) %>%
  tally()
  
```



## Question 3:

Using the jukebox data, what are the top 10 artists played during the "graveyard
shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=FALSE, fig.width=12, fig.height=6}
jukebox_grave <- jukebox %>%
  mutate(new_date = parse_date_time(jukebox$date_time, "%a %b %d %H %M! %S! %Y!")) %>%
  select(-date_time) %>%
  mutate(hour = hour(new_date)) %>%
  mutate(month = month(new_date)) %>%
  filter(hour < 8) %>%
  filter(month >= 9 | month <= 5) %>%
  group_by(artist) %>%
  tally() %>%
  arrange(desc(n)) %>%
  mutate("Times_Played" = n) %>%
  select(artist, Times_Played)

kable(head(jukebox_grave, 10), format = "markdown")

```

Woot woot! This result is self-explanatory. 

## Question 4:

We want to compare the volatility of 

* bitcoin prices
* gold prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=FALSE, fig.width=12, fig.height=6}
bitcoin <- Quandl("BAVERAGE/USD") %>% tbl_df()

bitcoin <- mutate(bitcoin, Avg = `24h Average`, Total.Volume = `Total Volume`) %>%
  select(-`24h Average`, -`Total Volume`) %>%
  arrange((Date)) %>%
  mutate(rel_change = 100*(Avg - lag(Avg))/Avg)

ggplot(data=bitcoin, aes(x=Date, y = rel_change)) +
  geom_line() +
  labs(x="Time", y="Relative Daily Price Change, as Percent") +
  ggtitle("Relative Daily Change in Bitcoin Price in USD, July 2010 - Present") +
  geom_smooth(n=100)
```

We can draw a few insights from this graph of daily realitve change in bitcoin price over the last five and a half years. We note that price volatility seems to rise and drop in a wave-like fashion, with peaks occuring in Fall 2010, Summer 2011, Summer 2012, Spring and late Fall/Winter 2013, early 2015, and somewhat in Fall 2015. With suprising reglarity, these "mounds" of increased volatility have happened approximately every nine months to twelve months. Importantly, within every mound prices are varying both positively and negatively, which is why the blue mean line never departs from the horizontal zero for long. 

Following from this first observation of mounds, we turn to practical advice for a foreign currency exchanger. We observe that the current date, April 2016, seems to be in a trough of non-volatility (i.e., not a mound). As the last mound peaked in Fall 2015, we can expect another mound of volatility to peak in about 4-7 months, in keeping with the nine month to twelve cycle. Therefore, we can expect 4-7 months of relative stability, a hospitable environment for investors looking to play it safe. But towards late Summer/Fall of 2016, we will likely begin to see greater positive and negative volatility as part of the upcoming mound. 

## Question 5:

Using the data loaded from Quandl below, plot a time series using `geom_line()`
comparing cheese and milk production in the US from 1930 to today. Comment on this.

* Cheese [page](https://www.quandl.com/data/USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB-Cheese-Production-Measured-In-Lb)
* Milk [page](https://www.quandl.com/data/USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB-Milk-Production-Measured-In-Lb)

```{r, echo=FALSE, fig.width=12, fig.height=6}
cheese <- Quandl("USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
milk <-  Quandl("USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()

milkcheese <- left_join(cheese, milk, by= "Date") %>%
  mutate(year = year(Date)) %>%
  arrange(year) %>%
  filter(year>=1930) %>%
  mutate("cheese" = Value.x) %>%
  mutate("milk" = Value.y) %>%
  select(year, cheese, milk) %>%
  mutate(cheese_change = 100*(cheese - lag(cheese))/cheese) %>%
  mutate(milk_change = 100*(milk - lag(milk))/milk)

c_avg <- mean(milkcheese$cheese_change, na.rm=TRUE)
c_avg

m_avg <- mean(milkcheese$milk_change, na.rm=TRUE)
m_avg

ggplot(data=milkcheese, aes(year)) +
  geom_line(aes(y=cheese), colour="blue") +
  labs(x="Year", y= "Cheese Produced, Lbs") +
  ggtitle("Cheese Quantity Produced by Year in America")

ggplot(data=milkcheese, aes(year)) +
  geom_line(aes(y=cheese_change), color="blue") +
  labs(x="Year", y="Percent Change in Yearly Cheese Price, Average in Black") +
  geom_hline(yintercept = 0, color="red") +
  geom_hline(yintercept = c_avg, color="black")

ggplot(data=milkcheese, aes(year)) +
  geom_line(aes(y=milk), colour="purple") +
  labs(x="Year", y= "Milk Produced, Lbs") +
  ggtitle("Milk Quantity Produced by Year in America")

ggplot(data=milkcheese, aes(year)) +
  geom_line(aes(y=milk_change), color="purple") +
  labs(x="Year", y="Percent Change in Yearly Milk Price, Average in Black") +
  geom_hline(yintercept = 0, color="red") +
  geom_hline(yintercept = m_avg, color="black")

```
  
These four graphs offer several insights into the American milk and cheese industry since 1930. Most clearly, we see that America has historically produced nearly 20 times more pounds of milk than it has of cheese. However, production in both sectors has seen fairly consistent growth since 1930, with the cheese sector particularly exploding since around 1970. 

More interesting than net weight of production is the volatility of production that graphs 2 (for cheese) and 4 (for milk) illustrate. Relative rise or fall in production has been extremely volatile, especially in the milk industry where streaks of more than a few years of either continuously positive or negative price change are rare. This is reflected in the very low average change in yearly production of milk, 0.83%. Cheese production is also volatile year-to-year, but experiences fewer and fewer yearly drops in production, especially after 1955. Though it produces less poundage than the milk industry, the relatively high average change in yearly cheese production of 3.52% speaks to the sustained growth of the American cheese industry. 
